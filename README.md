# Gaze-Glasses
As technologies develop for acquiring gaze behavior in real world social settings, robust methods are needed that minimize the time required for a trained observer to code behaviors. We record gaze behavior from asubjectwearingeye-trackingglassesduringanaturalistic interaction with three other people, with multiple objects that are referred to or manipulated during the interaction. The resulting gaze-in-world video from each interaction can be manually coded for different behaviors, but this processrequirestrainedbehavioralcodersandisextremely time-consuming. Instead, we use a neural network to detect objects, and a Viola-Jones framework with feature tracking to detect faces. The time sequence of events when the gaze lands within the object/face bounding boxes is processed for run lengths to determine “looks”, and we discuss optimization of run length parameters. The performance of the algorithm is compared against a bounding box ground truth and an expert holistic ground truth
